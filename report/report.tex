%----------------------------------------------------------------------------------------
%	CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[10pt,a4paper,oneside]{article}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{lipsum}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage[a4paper,left=2cm,right=2cm,top=2.5cm,bottom=2.5cm]{geometry}

%----------------------------------------------------------------------------------------
%	INFORMATION
%----------------------------------------------------------------------------------------

\title{Estudo de paralelismo num problema de simulação discreta}

\author{Filipe Figueiredo\footnote{Filipe Figueiredo - 201203559},
  Pedro Paredes\footnote{Pedro Paredes - 201205725}, DCC - FCUP}

\date{Janeiro 2016}

\renewcommand{\tablename}{Tabela}
\renewcommand{\figurename}{Figura}
\renewcommand{\refname}{Referências}
\newcommand{\BigO}[1]{\mathcal{O}(#1)}

\makeatletter
\makeatother

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Introdução}
\label{sec:intro}
Neste trabalho discutimos um problema de simulação determinística de
eventos discretos numa grelha e exploramos diferentes estratégias de
paralelismo possíveis.

Este tipo de problemas é notoriamente difícil de se paralelizar,
devido às dependências existentes nos dados e na topologia da
simulação provenientes das restrições impostas pelas mesmas. Neste
trabalho, a topologia da simulação é regular (uma grelha retangular),
o que permite que abordagens simples sejam efetivas, no entanto,
geralmente é necessário recorrer a métodos mais complexos como
computação especulativa.

Focamo-nos em três abordagem simples, que aproveitam diferentes
aspetos do problema. Além disso, exploramos diferentes esquemas de
redistribuição de trabalho de modo a podermos manter eficiência em
\textit{inputs} desbalanceados.

O resto deste relatório será organizado da seguinte forma. Na
Secção~\ref{sec:prob}, descrevemos o problema com algum pormenor e as
dificuldades em o paralelizar. Na Secção~\ref{sec:par}, introduzimos as
estratégias para paralelizar o problema e fazemos uma comparação
teórica entre elas. Na Secção~\ref{sec:res}, apresentamos os resultados
experimentais obtidos pela implementação de cada estratégia referida
na secção anterior. Finalmente, na Secção~\ref{sec:con}, fazemos
algumas notas finais.

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Descrição do problema}
\label{sec:prob}
O problema que pretendemos estudar é uma simulação numa grelha
retangular de $R$ linhas por $C$ colunas. Cada célula da grelha pode
estar vazia ou conter um dos seguintes elementos: uma pedra, um coelho
ou uma raposa. A simulação é feita iterativamente, ou seja, a partir
de uma geração inicial (o \textit{input}), representada por uma
distribuição de pedras, coelhos e raposas numa grelha, é produzida uma
nova geração seguindo um conjunto de regras fechado, e repetindo o
processo $N_G$ vezes até se obter a geração final (o
\textit{output}). Representamos por $N_i$ o número de coelhos e
raposas existentes na geração $i$.

As regras de construção de uma nova geração começam por primeiro mover
todos os coelhos simultaneamente para uma nova célula que esteja
vazia, seguindo uma ordem determinística. Seguidamente, as raposas são
movidas para uma célula vazia ou para uma célula que contenha um
coelho. O último caso representa uma raposa a comer um coelho, o que,
na prática, significa que o coelho que foi comido desaparece da
simulação na nova geração. Adicionalmente, tanto os coelhos como as
raposas podem procriar, duplicando-se cada animal num período
regular. A Figura~\ref{fig:sim} exemplifica duas gerações de uma
simulação.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
      \centering
      \includegraphics[height=1.6in]{grid1.png}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.4\textwidth}
      \centering
      \includegraphics[height=1.6in]{grid2.png}
    \end{subfigure}
    \caption{Exemplo de duas gerações de uma simulação}
    \label{fig:sim}
\end{figure}

A partir desta descrição simples do problema, é possível identificar
dependências fortes do mesmo. Em cada nova geração, a simulação das
raposas só pode ser iniciada após a conclusão da simulação de todos os
coelhos, pois os movimentos dos coelhos condicionam os movimentos das
raposas (a dependência é apenas local, ou seja, um coelho muito
afastado de uma certa raposa não condiciona o seu movimento, mas
aproveitar este tipo de observações requer um algoritmo mais complexo
e menos óbvio de paralelizar, não sendo por isso considerado). Assim,
existe aqui um ponto de sincronização necessário na execução da
simulação.

Adicionalmente, a simulação dos coelhos também impõe certas restrições
nos seus movimentos entre si. Além de serem obstáculos uns para os
outros, podem existir conflitos no movimento de dois ou mais coelhos
que se podem movimentar para a mesma célula. Nesse caso, apenas um
coelho sobrevive e, por isso, é necessário sincronizar os coelhos que,
após a resolução de conflitos, se mantêm. Isto é análogo para as
raposas.

É de notar que este tipo de simulação tem uma natureza exponencial
associada. Apesar de ser possível limitar o crescimento dos coelhos e
raposas atribuindo-lhes valores altos para o período para procriação,
as simulações mais ``interessantes'' (leia-se mais movimentadas)
rapidamente (em poucas gerações) preenchem a grelha a mais de
$50\%$. Por esta razão, não consideramos representações esparsas da
grelha (isto é, que não guardam a grelha diretamente como uma matriz),
pois, além de serem menos eficientes, têm aplicabilidade reduzida.

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------

\section{Estratégias de paralelização}
\label{sec:par}
Discutiremos três abordagens com diferentes focos e as suas vantagens
e desvantagens. A primeira abordagem (no código corresponde a
\texttt{TopologyEngine}) é uma abordagem orientada à topologia do
problema (ou \textit{topology driven parallelism}), ou seja, passa por
paralelizar o problema usando a grelha que serve de base da
simulação. A segunda estratégia (no código corresponde a
\texttt{DDEngine}) é orientada aos dados do problema (ou \textit{data
  driven parallelism}), ou seja, passa por paralelizar o próprio
\textit{input} do problema. Finalmente, a última abordagem (no código
corresponde a \texttt{MixedEngine}) é uma abordagem mista que combina
ideias das duas últimas abordagens.

Das três abordagens, as últimas duas permitem efetuar um
rebalanceamento dinâmico das unidades de trabalho. Experimentámos
várias alternativas que iremos discutir no fim desta secção.

\subsection{Estratégia orientada à topologia}
Esta estratégia é uma estratégia estática que divide a própria grelha
da simulação pelas várias \textit{threads}. Inicialmente, a grelha é
dividida em tiras horizontais iguais que são posteriormente
distribuídas uma para cada \textit{thread}. A distribuição está
ilustrada na Figura~\ref{fig:par1}, tendo como base o exemplo da
secção anterior. Para executar uma iteração da simulação, cada
\textit{thread} percorre a tira que lhe foi atribuída duas vezes (uma
para simular os coelhos e outra, análoga, para simular as raposas) e,
por cada vez, aplica as regras da simulação. Caso a nova posição de um
coelho ou raposa seja fora da tira de posições de uma \textit{thread},
então o animal é colocado numa \textit{queue} correspondente à
\textit{thread} cuja tira de posições contém a posição em
questão. Cada uma destas \textit{queues} é protegida por
\textit{mutexes} para ser \textit{thread safe}. Adicionalmente, as
\textit{threads} são sincronizadas usando barreiras depois da
simulação dos coelhos e depois da simulação das raposas para garantir
a correção da simulação, como foi discutido na secção anterior.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
      \centering
      \includegraphics[height=1.6in]{grid1_par1.png}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.4\textwidth}
      \centering
      \includegraphics[height=1.6in]{grid2_par1.png}
    \end{subfigure}
    \caption{Divisão de trabalho da paralelização orientada à topologia}
    \label{fig:par1}
\end{figure}

A vantagem desta estratégia está na sua simplicidade. Além de não
necessitar de nenhum tipo de sincronização complexa, a comunicação
entre \textit{threads} é extremamente reduzida, cada \textit{thread}
só comunica com no máximo duas outras (a que contém a tira de cima e a
de baixo). Assim, os conflitos entre \textit{threads} são reduzidos (a
contenção de \textit{threads} é rara). Porém, esta estratégia tem
várias desvantagens. Primeiramente, como a divisão é estática, se o
\textit{input} não for balanceado, podem surgir problemas de
escalabilidade (ainda que fosse possível aplicar as ideias que serão
usadas na estratégia mista para executar \textit{load
  balancing}). Além disso, devido ao facto que em cada iteração é
necessário percorrer a matriz da grelha por completo, a complexidade
temporal da simulação tem um \textit{bottleneck} no tamanho da grelha:
$R \times C$.

\subsection{Estratégia orientada aos dados}
Nesta estratégia o foco, como o próprio nome indica, é em paralelizar
os próprios dados. Por conseguinte, as unidades de trabalho
consideradas nesta estratégias são os próprios coelhos e
raposas. Inicialmente, os $N_1$ animais existentes são divididos de
uma forma \textit{round-robin} pelas \textit{threads} e guardados numa
estrutura de dados por cada \textit{thread} (uma \textit{queue}, por
exemplo). De modo a maximizar a localidade da distribuição, é feita
uma ordenação por posição (primeiro pela coordenada $y$ e depois pela
$x$), com o objetivo de ter uma distribuição semelhante à da
estratégia anterior) antes da divisão de trabalho. A distribuição está
ilustrada na Figura~\ref{fig:par2}, tendo como base o exemplo da
secção anterior. Após a divisão, a cada iteração, a simulação é
efetuada considerando apenas os animais correspondentes a cada
\textit{thread}, o que na prática corresponde a percorrer todos os
elementos da \textit{queue} de cada \textit{thread}. Apesar de só se
considerarem os animais existentes na geração atual, é mantida uma
matriz que representa a geração, com o objetivo de tornar mais
eficiente certas primitivas como o teste de quais células estão
livres. Adicionalmente, é necessário resolver os conflitos de
movimentos. Para tal, é mantida uma segunda matriz que vai sendo
preenchida com os animais nas novas posições e que, no fim, servirá
para cada \textit{thread} descartar os animais que ou foram comidos ou
que desapareceram num conflito. Nesta matriz podem haver conflitos ao
atualizar os seus valores e, como tal, é necessário proteger as suas
alterações, usando \textit{mutexes}. Experimentámos vários esquemas
diferentes de \textit{mutexes} para proteger a escrita nesta matriz,
desde um \textit{mutex} geral a um \textit{mutex} por célula. O que
funcionou melhor foi o de ter um \textit{mutex} por cada linha, o que
é justificável pelo facto da distribuição dos animais por
\textit{thread} ser feita pela ordem descrita anteriormente, o que faz
com que seja comum cada linha pertencer a apenas uma
\textit{thread}. Finalmente, assim como na estratégia anterior, as
\textit{threads} são sincronizadas usando barreiras depois da
simulação dos coelhos e depois da simulação das raposas.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
      \centering
      \includegraphics[height=1.6in]{grid1_par2.png}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.4\textwidth}
      \centering
      \includegraphics[height=1.6in]{grid2_par2.png}
    \end{subfigure}
    \caption{Divisão de trabalho da paralelização orientada aos dados}
    \label{fig:par2}
\end{figure}

Esta estratégia destaca-se da anterior por apenas fazer os cálculos
estritamente necessários por iteração. Assim, o \textit{bottleneck}
temporal de simular a geração $i$ é da ordem de $N_i$. Porém, para se
conseguir esta melhoria, o algoritmo base ficou mais complexo através
da presença das várias \textit{queues} e da forma de sincronização das
\textit{threads}. Ao contrário da estratégia orientada à topologia,
rebalancear o trabalho é muito mais natural para esta estratégia,
bastando movimentar unidades de trabalho entre as \textit{queues} de
cada \textit{thread}. Discutiremos com mais detalhes alternativas
possíveis para o processo de \textit{load balancing} no fim desta
secção.

\subsection{Estratégia mista}
A última estratégia que explorámos considera o melhor das duas
estratégias anteriores. Por um lado a divisão efetuada é análoga à da
estratégia orientada à topologia, onde se definem tiras horizontais
para serem atribuídas a cada \textit{thread}. Por outro lado, são
mantidas \textit{queues} por cada \textit{thread} como na estratégia
orientada aos dados, de modo a apenas percorrer os elementos relevantes
para a simulação da iteração atual. Adicionalmente, as tiras
atribuídas a cada \textit{thread} não são uniformes como na estratégia
original, mas tentam equilibrar o número de animais associadas a cada
\textit{thread}. Assim, é feita uma divisão usando um algoritmo
\textit{greedy} que vai crescendo cada tira até que ela inclua pelo
menos $\frac{N_1}{T}$ animais, sendo $T$ o número de
\textit{threads}. Esta distribuição está ilustrada
na Figura~\ref{fig:par3}, tendo como base o exemplo da secção
anterior.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
      \centering
      \includegraphics[height=1.6in]{grid1_par3.png}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.4\textwidth}
      \centering
      \includegraphics[height=1.6in]{grid2_par3.png}
    \end{subfigure}
    \caption{Divisão de trabalho da paralelização mista}
    \label{fig:par3}
\end{figure}

Esta estratégia mantêm a vantagem de comunicações reduzidas entre
\textit{threads} que a primeira estratégia possuía, ao mesmo tempo que
mantém o \textit{bottleneck} temporal a $N_i$ para a geração $i$. Com
esta nova divisão também se torna mais fácil rebalancear o trabalho,
bastando delinear novas tiras, respeitando as condições já referidas
(de ter aproximadamente $\frac{N_1}{T}$ animais por tira), e atualizar
as \textit{queues} respetivas.

\subsection{Rebalanceamento de trabalho}
Para as estratégias que permitem uma divisão dinâmica de trabalho,
começamos por descrever um conjunto de observações
importantes. Primeiro, é importante notar que quando é feita uma
redistribuição de trabalho, não é viável que esta não seja global, ou
seja, que não inclua todas as \textit{threads}. Isto deve-se ao facto
de que é importante sincronizar o trabalho das \textit{threads} após
cada parte da simulação, visto que mesmo que alguma \textit{thread}
não participasse na redistribuição de trabalho, teria que ficar à
espera que as restantes terminassem. Isto elimina vários tipos de
estratégias clássicas como \textit{work sharing} entre
\textit{threads}. Outra observação importante passa por notar que não
é eficiente redistribuir o trabalho a cada iteração, pois ambas as
estratégias dinâmicas usam algoritmos pesados temporalmente para
redistribuição de trabalho. Além disso, obter o valor de $N_i$ para
decidir o quão desbalanceadas estão as \textit{queues} também requer
um algoritmo pesado, sendo por isso também pouco eficiente fazê-lo a
cada iteração. Assim, optámos por apenas redistribuir trabalho no
máximo a cada $\sqrt{N_G}$ gerações. Antes de efetuar a
redistribuição, aglomera-se o valor de $N_i$ somando o tamanho de
todas as \textit{queues} e, se alguma das \textit{queues} tiver mais de
$25\%$ elementos do que $\frac{N_i}{T}$, então é feita uma
redistribuição. O valor de $25\%$ foi obtido empiricamente.

%----------------------------------------------------------------------------------------
%	SECTION 4
%----------------------------------------------------------------------------------------

\section{Resultados e discussão}
\label{sec:res}
Para testar os algoritmos e estratégias descritas na secção anterior,
implementamos as ideias apresentadas em \texttt{C++} usando
\texttt{pthreads} como ambiente de paralelismo. Posteriormente,
testamos cada abordagem com \textit{inputs} diferentes, que exploram
diferentes vantagens e desvantagens das várias estratégias. Os
diferentes \textit{inputs} usados estão sumarizados na
Tabela~\ref{tab:inps}. Omitimos uma implementação puramente sequencial
por ser análoga à implementação paralela obtida retirando os
\textit{mutexes} e barreiras, tendo as nossas experiências mostrado
que a diferença temporal entre esta e a versão paralela com uma única
\textit{thread} é desprezável.

\begin{table}[H]
  \small
  \caption{\textit{Inputs} usados nos testes}
  \label{tab:inps}
  \centering
  \begin{tabular}{|c|c|c|c|c|l|l|}
    \hline
    Grelha   & $N_1$ & $R$ & $C$ & $N_G$  & Ficheiro                    & Nota \\ \hline \hline
    {\tt S1} & 300   & 100 & 100 & 10000 & {\tt input100x100\_unbal01} & \textit{Input} desbalanceado \\ \hline
    {\tt S2} & 300   & 100 & 100 & 10000 & {\tt input100x100\_unbal02} & \textit{Input} desbalanceado \\ \hline
    {\tt M1} & 1400  & 200 & 200 & 10000 & {\tt input200}              & \textit{Input} denso \\ \hline
    {\tt L1} & 4     & 500 & 500 & 2000  & {\tt input500}              & \textit{Input} muito esparso \\ \hline
  \end{tabular}
\end{table}

Identificamos as estratégias a testar por: {\tt TP}, a estratégia
orientada à topologia; {\tt DD-0}, a estratégia orientada aos dados
sem \textit{load balancing}; {\tt DD-1}, a estratégia orientada aos
dados com \textit{load balancing}; {\tt MX-0}, a estratégia mista sem
\textit{load balancing}; {\tt MX-1}, a estratégia mista com
\textit{load balancing}. Os resultados estão sumarizados na
Figura~\ref{fig:res} e na Tabela~\ref{tbl:m1} e Tabela~\ref{tbl:l1}
para {\tt M1} e {\tt L1}, tendo sido corridos com 1, 2, 4, 8 e 16 {\it
  threads}. É de notar que não foi incluída uma versão puramente
sequencial por ser completamente análoga à de 1 {\it thread} sem os
construtores paralelos (barreiras e {\it mutexes}), mas também que
comparando a execução dos dois em diferentes testes a diferença de
tempos foi desprezável, menos de 1$\%$.

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \includegraphics[width=\textwidth]{S1.png}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \includegraphics[width=\textwidth]{S2.png}
    \end{subfigure}

    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \includegraphics[width=\textwidth]{M1.png}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \includegraphics[width=\textwidth]{L1.png}
    \end{subfigure}

    \caption{Gráficos dos resultados experimentais}
    \label{fig:res}
\end{figure}

\begin{table}[t]
  \begin{subtable}[b]{0.49\textwidth}
    \centering
    \scriptsize
    \begin{tabular}{|l|r|r|r|}
      \hline
      Alg. & $n_{th}$ & Tempo (s) & {\it speedup} \\ \hline
      \multicolumn{1}{|c|}{{\tt TP}} & 1 & 68.38 & 1.00 \\ \cline{ 2- 4}
      & 2 & 36.60 & 1.87 \\ \cline{ 2- 4}
      & 4 & 19.59 & 3.49 \\ \cline{ 2- 4}
      & 8 & 12.90 & 5.30 \\ \cline{ 2- 4}
      & 16 & 9.30 & 7.36 \\ \hline
      \multicolumn{ 1}{|c|}{{\tt DD-0}}  & 1 & 83.64 & 1.00 \\ \cline{ 2- 4}
      & 2 & 62.34 & 1.34 \\ \cline{ 2- 4}
      & 4 & 47.11 & 1.78 \\ \cline{ 2- 4}
      & 8 & 36.39 & 2.30 \\ \cline{ 2- 4}
      & 16 & 34.35 & 2.43 \\ \hline
      \multicolumn{ 1}{|c|}{{\tt DD-1}}  & 1 & 78.69 & 1.00 \\ \cline{ 2- 4}
      & 2 & 55.41 & 1.42 \\ \cline{ 2- 4}
      & 4 & 37.49 & 2.10 \\ \cline{ 2- 4}
      & 8 & 21.16 & 3.72 \\ \cline{ 2- 4}
      & 16 & 18.94 & 4.15 \\ \hline
      \multicolumn{ 1}{|c|}{{\tt MX-0}}  & 1 & 73.72 & 1.00 \\ \cline{ 2- 4}
      & 2 & 47.90 & 1.54 \\ \cline{ 2- 4}
      & 4 & 29.58 & 2.49 \\ \cline{ 2- 4}
      & 8 & 17.52 & 4.21 \\ \cline{ 2- 4}
      & 16 & 12.99 & 5.68 \\ \hline
      \multicolumn{ 1}{|c|}{{\tt MX-1}}  & 1 & 72.49 & 1.00 \\ \cline{ 2- 4}
      & 2 & 46.57 & 1.56 \\ \cline{ 2- 4}
      & 4 & 27.75 & 2.61 \\ \cline{ 2- 4}
      & 8 & 18.48 & 3.92 \\ \cline{ 2- 4}
      & 16 & 12.46 & 5.82 \\ \hline
    \end{tabular}
    \caption{Resultados para {\tt M1}}
    \label{tbl:m1}
  \end{subtable}
  ~
  \begin{subtable}[b]{0.49\textwidth}
    \centering
    \scriptsize
    \begin{tabular}{|l|r|r|r|}
      \hline
      Alg. & $n_{th}$ & Tempo (s) & {\it speedup} \\ \hline
      \multicolumn{1}{|c|}{{\tt TP}} & 1 & 33.25 & 1.00 \\ \cline{ 2- 4}
                             & 2 & 21.02 & 1.58 \\ \cline{ 2- 4}
                             & 4 & 11.50 & 2.89 \\ \cline{ 2- 4}
                             & 8 & 6.56 & 5.07 \\ \cline{ 2- 4}
                             & 16 & 4.19 & 7.93 \\ \hline
      \multicolumn{ 1}{|c|}{{\tt DD-0}} & 1 & 36.78 & 1.00 \\ \cline{ 2- 4}
                             & 2 & 34.66 & 1.06 \\ \cline{ 2- 4}
                             & 4 & 34.96 & 1.05 \\ \cline{ 2- 4}
                             & 8 & 35.57 & 1.03 \\ \cline{ 2- 4}
                             & 16 & 36.19 & 1.02 \\ \hline
      \multicolumn{ 1}{|c|}{{\tt DD-1}} & 1 & 35.67 & 1.00 \\ \cline{ 2- 4}
                             & 2 & 22.84 & 1.56 \\ \cline{ 2- 4}
                             & 4 & 14.66 & 2.43 \\ \cline{ 2- 4}
                             & 8 & 7.99 & 4.46 \\ \cline{ 2- 4}
                             & 16 & 5.95 & 6.00 \\ \hline
      \multicolumn{ 1}{|c|}{{\tt MX-0}} & 1 & 33.94 & 1.00 \\ \cline{ 2- 4}
                             & 2 & 23.16 & 1.47 \\ \cline{ 2- 4}
                             & 4 & 14.37 & 2.36 \\ \cline{ 2- 4}
                             & 8 & 8.34 & 4.07 \\ \cline{ 2- 4}
                             & 16 & 5.63 & 6.03 \\ \hline
      \multicolumn{ 1}{|c|}{{\tt MX-1}} & 1 & 30.74 & 1.00 \\ \cline{ 2- 4}
                             & 2 & 19.80 & 1.55 \\ \cline{ 2- 4}
                             & 4 & 10.88 & 2.83 \\ \cline{ 2- 4}
                             & 8 & 6.78 & 4.53 \\ \cline{ 2- 4}
                             & 16 & 5.08 & 6.05 \\ \hline
    \end{tabular}
    \caption{Resultados para {\tt L1}}
    \label{tbl:l1}
  \end{subtable}
\end{table}

É possível observar que para todos os métodos, os {\it speedups} a
partir de 4 {\it threads} começaram a deteriorar-se, pois a
necessidade de sincronizar repetidamente as {\it threads} nas várias
gerações impede que seja explorado mais paralelismo. Segundo testes
extra, omitidos por brevidade, a maior parte do tempo apenas cerca de
$60\%$ das {\it threads} estavam ativas (para 2 ou mais {\it
  threads}).

O resultado mais relevante dos testes efetuados foi que o método que
teve os melhores resultados foi o {\tt TP}, tendo obtido perto de 8
como {\it speedup} para 16 {\it threads} e à volta de 5 para 8 {\it
  threads}. Segundo a discussão teórica inicial, este método teria
dificuldades em ter bons resultados em grelhas desbalanceadas, pois a
sua divisão é completamente estática. Porém, apesar dos métodos {\tt
  MX} terem um comportamento semelhante em termos de escalabilidade, o
{\tt TP} conseguiu melhores {\it speedups} e de uma forma geral
melhores tempos para todas as instâncias. A razão para tal é que é
muito difícil obrigar o {\it input} a ser desbalanceado de forma a
prejudicar a eficiência do {\tt TP}. Por exemplo, apesar do {\tt L1}
ser muito esparso e desbalanceado, os animais rapidamente se espalham
pela grelha (mesmo tendo valores altos de idades de procriação), sendo
que a computação é mais pesada depois de se espalharem, por haverem
mais unidades de trabalho. É possível ``forçar'' o {\tt TP} a ter um
comportamento deteriorado, por exemplo, colocando tiras de pedras na
grelha de forma a conter os animais em certas secções, desbalanceando
permanentemente o {\it input}. Para este tipo de simulação tanto o
{\tt DD-1} como o {\tt MX-1} terão muito mais sucesso. Não foram
incluídos testes nesse sentido por brevidade e também por esse tipo de
simulações não ser ``natural'' ao tipo de problema.

Como seria de esperar, o {\tt DD-0} teve a pior {\it performance},
devido ao facto que não aproveita nenhum tipo de localidade para
dividir o trabalho e rapidamente várias {\it threads} ficam sem
trabalho. Já o {\tt DD-1} teve algum sucesso, comparável ao dos
restantes métodos, em termos de escalabilidade, porém foi mais lento
pois a simulação base é mais pesada.

%----------------------------------------------------------------------------------------
%	SECTION 5
%----------------------------------------------------------------------------------------

\section{Conclusão e notas finais}
\label{sec:con}
Neste trabalho explorámos várias abordagens com diferentes focos para
paralelizar um problema de simulação discreta numa grelha
retangular. Além disso, implementámos cada um em {\tt C++} usando {\tt
  pthreads} para obter um código paralelo no qual efetuámos vários
testes com \textit{inputs} de naturezas e tamanhos diferentes.

Os resultados dos testes efetuados mostram que foi possível obter {\it
  speedups} à volta de $\frac{n_{th}}{2}$ para os melhores métodos e
foi possível observar que os métodos mais eficientes foram os que
privilegiaram a simplicidade da computação base e aproveitaram a
localidade dos dados. Foi possível efetuar diferentes análises mais
detalhadas, como os pontos em que foram feitas partilhas de unidades
de trabalho entre {\it threads} para as várias estratégias ou o tempo
médio de execução por cada ponto de sincronização, mas por brevidade
foram omitidas e os seus resultados foram incluídos nas conclusões
retiradas da análise feita.

%\bibliographystyle{plain}
%\bibliography{report}

\end{document}
